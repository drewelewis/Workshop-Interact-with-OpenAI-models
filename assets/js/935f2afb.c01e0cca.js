"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Welcome","href":"/Workshop-Interact-with-OpenAI-models/","docId":"Welcome","unlisted":false},{"type":"link","label":"Get started","href":"/Workshop-Interact-with-OpenAI-models/setup","docId":"Get-Started","unlisted":false},{"type":"category","label":"Core Concepts","collapsible":true,"collapsed":false,"className":"red","items":[{"type":"link","label":"AI Models & Deployments","href":"/Workshop-Interact-with-OpenAI-models/ai-models","docId":"concepts/Explore-Models","unlisted":false},{"type":"link","label":"Large Language Model (LLM)","href":"/Workshop-Interact-with-OpenAI-models/llms","docId":"concepts/Understand-LLMs","unlisted":false},{"type":"link","label":"Tokenization","href":"/Workshop-Interact-with-OpenAI-models/tokenization","docId":"concepts/Understand-Tokens","unlisted":false},{"type":"link","label":" Generative AI","href":"/Workshop-Interact-with-OpenAI-models/generative-ai","docId":"concepts/Generative-AI","unlisted":false}]},{"type":"category","label":" Labs","collapsible":true,"collapsed":false,"className":"red","items":[{"type":"link","label":"Basic Prompting","href":"/Workshop-Interact-with-OpenAI-models/labs/Basic-Prompting","docId":"labs/Basic-Prompting","unlisted":false},{"type":"link","label":"Advanced Techniques","href":"/Workshop-Interact-with-OpenAI-models/labs/Advanced-Techniques","docId":"labs/Advanced-Techniques","unlisted":false},{"type":"link","label":"Response grounding","href":"/Workshop-Interact-with-OpenAI-models/labs/Response-grounding","docId":"labs/Response-grounding","unlisted":false},{"type":"link","label":"Ways of \'learning\'","href":"/Workshop-Interact-with-OpenAI-models/labs/Ways-of-learning","docId":"labs/Ways-of-learning","unlisted":false},{"type":"link","label":"Function Calling","href":"/Workshop-Interact-with-OpenAI-models/labs/Function-Calling","docId":"labs/Function-Calling","unlisted":false},{"type":"link","label":"Create Images","href":"/Workshop-Interact-with-OpenAI-models/labs/Create-Images","docId":"labs/Create-Images","unlisted":false}]},{"type":"category","label":"Wrap-Up","collapsible":true,"collapsed":false,"className":"red","items":[{"type":"link","label":"What We\'ve Learned","href":"/Workshop-Interact-with-OpenAI-models/summary","docId":"summary/Summary","unlisted":false},{"type":"link","label":"Things To Try Next","href":"/Workshop-Interact-with-OpenAI-models/next-steps","docId":"summary/Next-Steps","unlisted":false},{"type":"link","label":"Instructor-Led (Event)","href":"/Workshop-Interact-with-OpenAI-models/at-home","docId":"summary/At-home","unlisted":false}]}]},"docs":{"concepts/Explore-Models":{"id":"concepts/Explore-Models","title":"AI Models & Deployments","description":"What is an AI Model?","sidebar":"tutorialSidebar"},"concepts/Generative-AI":{"id":"concepts/Generative-AI","title":" Generative AI","description":"Most people are familiar with natural language generative AI from applications like ChatGPT, but you can use these models for much more than chatbots. In this section, we\'ll explore some other useful applications of these models.","sidebar":"tutorialSidebar"},"concepts/Understand-LLMs":{"id":"concepts/Understand-LLMs","title":"Large Language Model (LLM)","description":"A large language model (LLM) is a type of AI that can process and produce natural language text. It learns from a massive amount of text data such as books, articles, and web pages to discover patterns and rules of language from them.","sidebar":"tutorialSidebar"},"concepts/Understand-Tokens":{"id":"concepts/Understand-Tokens","title":"Tokenization","description":"We\'ve mentioned \\"tokens\\" a few times in previous lessons, but we didn\'t explain what those were and why they matter. Let\'s discuss that now.","sidebar":"tutorialSidebar"},"Get-Started":{"id":"Get-Started","title":"Get started","description":"- Use your own laptop.","sidebar":"tutorialSidebar"},"labs/Advanced-Techniques":{"id":"labs/Advanced-Techniques","title":"Advanced Techniques","description":"As we\'ve seen, natural language Generative AI models can produce unexpected or unwanted responses to prompts. This can be caused by any number of factors, including:","sidebar":"tutorialSidebar"},"labs/Basic-Prompting":{"id":"labs/Basic-Prompting","title":"Basic Prompting","description":"Prompt Engineering is the process of adding additional context to the prompt to provide \\"grounding\\" to the AI model and make it more likely to produce the desired response and less likely to produce undesirable outputs. For example, in a chatbot application, the system would inject additional instructions and data into the prompt before the user\'s actual input, to provide context to the model.","sidebar":"tutorialSidebar"},"labs/Create-Images":{"id":"labs/Create-Images","title":"Create Images","description":"The Azure OpenAI service includes the DALL-E model, which you can use to generate original images based on natural language prompts.","sidebar":"tutorialSidebar"},"labs/Function-Calling":{"id":"labs/Function-Calling","title":"Function Calling","description":"The latest versions of gpt-35-turbo and gpt-4 are fine-tuned to work with functions and are able to both determine when and how a function should be called. If one or more functions are included in your request, the model determines if any of the functions should be called based on the context of the prompt. When the model determines that a function should be called, it responds with a JSON object including the arguments for the function.","sidebar":"tutorialSidebar"},"labs/Response-grounding":{"id":"labs/Response-grounding","title":"Response grounding","description":"Building on top of the system message approach, grounding the response means diving into what is it you want your agent to do/not do. Below are a few examples of ways you can build a responsible agent that will perform well in the real world and when bad actors are trying to deter the agent.","sidebar":"tutorialSidebar"},"labs/Ways-of-learning":{"id":"labs/Ways-of-learning","title":"Ways of \'learning\'","description":"This section discusses prompt engineering techniques that can help LLMs solve certain problems more effectively.","sidebar":"tutorialSidebar"},"summary/At-home":{"id":"summary/At-home","title":"Instructor-Led (Event)","description":"2. Self-Guided Learning","sidebar":"tutorialSidebar"},"summary/Next-Steps":{"id":"summary/Next-Steps","title":"Things To Try Next","description":"Completed the workshop already? Need something else to do? Here are some other things to try","sidebar":"tutorialSidebar"},"summary/Summary":{"id":"summary/Summary","title":"What We\'ve Learned","description":"We hope that in the last hour, you\'ve learned what natural language generative AI models are and how they work, how to access them in Azure OpenAI Service, and started on the path to building applications with them. Here are some key points to remember:","sidebar":"tutorialSidebar"},"Welcome":{"id":"Welcome","title":"Welcome","description":"This is a **60-minute** workshop that will give you a hands-on introduction to the core concepts and best practices for interacting with OpenAI models.","sidebar":"tutorialSidebar"}}}')}}]);